{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\zhpek\\Desktop\\C4I\\Challenge 4\\aml_config\\config.json\n"
     ]
    }
   ],
   "source": [
    "import azureml\n",
    "from azureml.core import Workspace, Run\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from azureml.core.model import Model\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.train.automl.run import AutoMLRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train-on-remote-vm': Experiment(Name: train-on-remote-vm,\n",
       " Workspace: pekamlworkspace),\n",
       " 'aks-compute-trial': Experiment(Name: aks-compute-trial,\n",
       " Workspace: pekamlworkspace),\n",
       " 'sklearn-mnist': Experiment(Name: sklearn-mnist,\n",
       " Workspace: pekamlworkspace),\n",
       " 'automl-local-classification': Experiment(Name: automl-local-classification,\n",
       " Workspace: pekamlworkspace),\n",
       " 'tf-mnist': Experiment(Name: tf-mnist,\n",
       " Workspace: pekamlworkspace),\n",
       " 'automl-pipeline-classification': Experiment(Name: automl-pipeline-classification,\n",
       " Workspace: pekamlworkspace),\n",
       " '10k-Diabetes-with-AutoML': Experiment(Name: 10k-Diabetes-with-AutoML,\n",
       " Workspace: pekamlworkspace),\n",
       " 'c4ts-challenge4': Experiment(Name: c4ts-challenge4,\n",
       " Workspace: pekamlworkspace)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws.experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML_ee562a66-ffe1-4e7f-b6a9-1641937a61e8\n",
      "AutoML_ece6d8e3-f37a-49c3-b601-c35261eab752\n"
     ]
    }
   ],
   "source": [
    "experiment_name = 'c4ts-challenge4' # Replace this with any project name from previous cell\n",
    "experiment = ws.experiments[experiment_name]\n",
    "#ml_run = AutoMLRun(experiment=experiment, run_id=run_id)\n",
    "selected_metric = 'AUC_weighted'\n",
    "#summary_df = pd.DataFrame(index = ['Type', 'Status', 'Primary Metric', 'Iterations', 'Compute', 'Name'])\n",
    "#pattern = re.compile('^AutoML_[^_]*$')\n",
    "runs = list(experiment.get_runs())\n",
    "#model_dict = {}\n",
    "models_df = pd.DataFrame(index = [selected_metric, 'run'])\n",
    "for run in runs[:2]:\n",
    "    \n",
    "    aml_run = AutoMLRun(experiment = experiment, run_id = run.id)\n",
    "    print(run.id)\n",
    "    best_run, __ = aml_run.get_output()\n",
    "    metrics = best_run.get_metrics()\n",
    "    \n",
    "    if selected_metric in metrics:\n",
    "        #model_dict[run.id]= {'run': aml_run}\n",
    "        #model_dict[run.id][selected_metric] = metrics[selected_metric]\n",
    "        models_df[run.id] = [metrics[selected_metric],aml_run]\n",
    "        \n",
    "models_df = models_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC_weighted</th>\n",
       "      <th>run</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AutoML_ee562a66-ffe1-4e7f-b6a9-1641937a61e8</th>\n",
       "      <td>0.820556</td>\n",
       "      <td>Run(Experiment: c4ts-challenge4,\\nId: AutoML_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AutoML_ece6d8e3-f37a-49c3-b601-c35261eab752</th>\n",
       "      <td>0.787947</td>\n",
       "      <td>Run(Experiment: c4ts-challenge4,\\nId: AutoML_e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            AUC_weighted  \\\n",
       "AutoML_ee562a66-ffe1-4e7f-b6a9-1641937a61e8     0.820556   \n",
       "AutoML_ece6d8e3-f37a-49c3-b601-c35261eab752     0.787947   \n",
       "\n",
       "                                                                                           run  \n",
       "AutoML_ee562a66-ffe1-4e7f-b6a9-1641937a61e8  Run(Experiment: c4ts-challenge4,\\nId: AutoML_e...  \n",
       "AutoML_ece6d8e3-f37a-49c3-b601-c35261eab752  Run(Experiment: c4ts-challenge4,\\nId: AutoML_e...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc = [model_dict[k][selected_metric] for k in model_dict]\n",
    "#runlist = [model_dict[k]['run'] for k in model_dict]\n",
    "#best_run = runlist[acc.index(max(acc))]\n",
    "#best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>c4ts-challenge4</td><td>AutoML_ee562a66-ffe1-4e7f-b6a9-1641937a61e8</td><td>automl</td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/50fb2758-5add-47ee-b8f2-9c9ae596fed5/resourceGroups/pekamlrg/providers/Microsoft.MachineLearningServices/workspaces/pekamlworkspace/experiments/c4ts-challenge4/runs/AutoML_ee562a66-ffe1-4e7f-b6a9-1641937a61e8\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: c4ts-challenge4,\n",
       "Id: AutoML_ee562a66-ffe1-4e7f-b6a9-1641937a61e8,\n",
       "Type: automl,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = models_df[selected_metric].astype(float).idxmax()\n",
    "best_run = models_df.loc[run_id, 'run']\n",
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model AutoMLee562a66fbest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AutoMLee562a66fbest'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = best_run.register_model(description = 'AutoML Model Registration', tags = None)\n",
    "model_id = best_run.model_id\n",
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No issues found in the SDK package versions.\n"
     ]
    }
   ],
   "source": [
    "rundl = AutoMLRun(experiment = experiment, run_id = best_run.id)\n",
    "dependencies = rundl.get_run_sdk_dependencies(iteration = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from utils import scaler\n",
    "\n",
    "artifacts = rundl.get_file_names()\n",
    "\n",
    "for f in artifacts:\n",
    "    rundl.download_file(f)\n",
    "\n",
    "p = pickle.load(open('pca_transform.pkl','rb'))\n",
    "s = pickle.load(open('scaler.pkl','rb'))\n",
    "scaler_mean = list(s.mean)\n",
    "scaler_var = list(s.var)\n",
    "scaler_index = list(s.mean.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pca_transform.pkl', 'scaler.pkl', 'utils.py']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifacts = ['pca_transform.pkl', 'scaler.pkl','utils.py']\n",
    "artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AutoMLee562a66fbest'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile score_sparkml.py\n",
    "#s_mean = {scaler_mean}\n",
    "#s_var = {scaler_var}\n",
    "#s_\n",
    "\n",
    "#def scale(x):\n",
    "#    result = (x - {scaler_mean}) / np.sqrt({scaler_var})\n",
    "#    return (result)\n",
    "\n",
    "score_script = \"\"\"\n",
    " \n",
    "import pickle\n",
    "import json\n",
    "import numpy\n",
    "import azureml.train.automl\n",
    "from sklearn.externals import joblib\n",
    "from azureml.core.model import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import scaler\n",
    "\n",
    "def cleanLongLat(l):\n",
    "    split = l.str.split(',', expand=True)\n",
    "    split = (split[0]+'.'+[i if len(i)>1 else i+'0' for i in split[1]]).astype(float)\n",
    "    return(split)\n",
    "\n",
    "\n",
    "def init():\n",
    "    from utils import scaler\n",
    "\n",
    "    global model\n",
    "    global pca_transform\n",
    "    global s\n",
    "        \n",
    "    s = scaler(pd.DataFrame([1,2]))\n",
    "    model_id = \"{model_id}\"\n",
    "    model_path = Model.get_model_path(model_name = model_id)\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    model = joblib.load(model_path)\n",
    "    pca_transform = pickle.load(open('pca_transform.pkl', 'rb'))\n",
    "    s = pickle.load(open('scaler.pkl','rb'))\n",
    "\n",
    "def run(rawdata):\n",
    "    try:\n",
    "        df = json.loads(j_test)['data']\n",
    "        df = pd.DataFrame.from_records(df)\n",
    "        df['Latitude'] = cleanLongLat(df['Latitude'])\n",
    "        df['Longitude'] = cleanLongLat(df['Longitude'])\n",
    "        df.drop(['Machine_ID', 'District'], axis=1, inplace=True)\n",
    "        df.drop('Failure_NextHour', axis = 1, inplace=True)\n",
    "        df = df.apply(pd.to_numeric)\n",
    "        data = pca_transform.transform(s.scale(df))\n",
    "        result = best_model.predict(data) #Changed to best_model here\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({{\"error\": result}})\n",
    "    return json.dumps({{\"result\":result.tolist()}}) \n",
    "    \n",
    "\"\"\".format(model_id = model_id)#, scaler_mean = scaler_mean, scaler_var = scaler_var)\n",
    "\n",
    "with open(\"score.py\", \"w\") as file:\n",
    "    file.write(score_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'myenv.yml'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "myenv = CondaDependencies.create(conda_packages=['numpy','scikit-learn','pandas'], pip_packages=['azureml-sdk[automl]'])\n",
    "\n",
    "conda_env_file_name = 'myenv.yml'\n",
    "myenv.save_to_file('.', conda_env_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running................................................\n",
      "SucceededImage creation operation finished for image c4tsimg2:19, operation \"Succeeded\"\n",
      "Wall time: 5min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.image import Image, ContainerImage\n",
    "\n",
    "image_config = ContainerImage.image_configuration(runtime= \"python\",\n",
    "                                                  execution_script = 'score.py',\n",
    "                                                  conda_file = conda_env_file_name,\n",
    "                                                  dependencies = artifacts,\n",
    "                                                  description = \"Image for c4ts Challenge 4\")\n",
    "\n",
    "image = Image.create(name = \"c4tsimg2\",\n",
    "                     # this is the model object \n",
    "                     models = [model],\n",
    "                     image_config = image_config, \n",
    "                     workspace = ws)\n",
    "\n",
    "image.wait_for_creation(show_output = True)\n",
    "\n",
    "if image.creation_state == 'Failed':\n",
    "    print(\"Image build log at: \" + image.image_build_log_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pekamlwoacrjcvuohfw.azurecr.io/c4tsimg2:19'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.image_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
    "                                               memory_gb=1, \n",
    "                                               tags={\"data\": \"c4ts4\",  \"method\" : \"automl\"}, \n",
    "                                               description='C4TS Challenge 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating service\n",
      "Running...............................\n",
      "FailedACI service creation operation finished, operation \"Failed\"\n",
      "Service creation polling reached terminal state, unexpected error response:\n",
      "{'code': 'AciDeploymentFailed', 'message': 'Aci Deployment failed', 'details': [{'code': 'CrashLoopBackOff', 'message': \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\nPlease check the logs for your container instance c4ts-svc.\\nYou can also try to run image pekamlwoacrjcvuohfw.azurecr.io/c4tsimg2:19 locally. Please refer to http://aka.ms/debugimage for more information.\"}]}\n",
      "Unhealthy\n",
      "Wall time: 3min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from azureml.core.webservice import Webservice\n",
    "\n",
    "service = Webservice.deploy_from_image(workspace=ws,\n",
    "                                       name='c4ts-svc',\n",
    "                                       deployment_config=aciconfig,\n",
    "                                       image=image)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-09T08:53:56,126111042+00:00 - iot-server/run \n",
      "2019-01-09T08:53:56,126777662+00:00 - rsyslog/run \n",
      "2019-01-09T08:53:56,128219804+00:00 - gunicorn/run \n",
      "ok: run: gunicorn: (pid 14) 0s\n",
      "ok: run: nginx: (pid 12) 0s\n",
      "ok: run: rsyslog: (pid 13) 0s\n",
      "2019-01-09T08:53:56,133294053+00:00 - nginx/run \n",
      "ok: run: rsyslog: (pid 13) 0s\n",
      "ok: run: rsyslog: (pid 13) 0s\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2019-01-09T08:53:56,309872922+00:00 - iot-server/finish 1 0\n",
      "2019-01-09T08:53:56,311016455+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "{\"timestamp\": \"2019-01-09T08:53:56.560825Z\", \"message\": \"Starting gunicorn 19.6.0\", \"host\": \"wk-caas-895de745f7ba4271867822c90175767b-28255d2ca56dd042d2a6a2\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Starting gunicorn %s\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-09T08:53:56.561595Z\", \"message\": \"Listening at: http://127.0.0.1:9090 (14)\", \"host\": \"wk-caas-895de745f7ba4271867822c90175767b-28255d2ca56dd042d2a6a2\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Listening at: %s (%s)\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-09T08:53:56.561702Z\", \"message\": \"Using worker: sync\", \"host\": \"wk-caas-895de745f7ba4271867822c90175767b-28255d2ca56dd042d2a6a2\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Using worker: %s\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-09T08:53:56.562289Z\", \"message\": \"worker timeout is set to 300\", \"host\": \"wk-caas-895de745f7ba4271867822c90175767b-28255d2ca56dd042d2a6a2\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-09T08:53:56.563202Z\", \"message\": \"Booting worker with pid: 39\", \"host\": \"wk-caas-895de745f7ba4271867822c90175767b-28255d2ca56dd042d2a6a2\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Booting worker with pid: %s\", \"stack_info\": null}\n",
      "Initializing logger\n",
      "{\"timestamp\": \"2019-01-09T08:54:02.557136Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Starting up app insights client\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-895de745f7ba4271867822c90175767b-28255d2ca56dd042d2a6a2\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-09T08:54:02.557389Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Starting up request id generator\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-895de745f7ba4271867822c90175767b-28255d2ca56dd042d2a6a2\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-09T08:54:02.557499Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Starting up app insight hooks\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-895de745f7ba4271867822c90175767b-28255d2ca56dd042d2a6a2\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-09T08:54:02.557629Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Invoking user's init function\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-895de745f7ba4271867822c90175767b-28255d2ca56dd042d2a6a2\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"root\", \"stack_info\": null}\n",
      "2019-01-09 08:54:02,562 | azureml.core.run | DEBUG | Could not load run context Failed to load a submitted run, if outside of an execution context, use project.start_run to initialize an azureml.core.Run., switching offline: False\n",
      "2019-01-09 08:54:02,562 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\n",
      "2019-01-09 08:54:02,562 | azureml.core.model | DEBUG | RunEnvironmentException: Failed to load a submitted run, if outside of an execution context, use project.start_run to initialize an azureml.core.Run.\n",
      "2019-01-09 08:54:02,562 | azureml.core.model | DEBUG | version is None. Latest version is 3\n",
      "2019-01-09 08:54:02,562 | azureml.core.model | DEBUG | Found model path at azureml-models/AutoMLee562a66fbest/3/model.pkl\n",
      "{\"timestamp\": \"2019-01-09T08:54:02.577198Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"User's init function failed\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-895de745f7ba4271867822c90175767b-28255d2ca56dd042d2a6a2\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"ERROR\", \"logger\": \"root\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-09T08:54:02.577614Z\", \"message\": \"{\\\"requestId\\\": \\\"00000000-0000-0000-0000-000000000000\\\", \\\"message\\\": \\\"Encountered Exception Traceback (most recent call last):\\\\n  File \\\\\\\"/var/azureml-app/aml_blueprint.py\\\\\\\", line 109, in register\\\\n    main.init()\\\\n  File \\\\\\\"/var/azureml-app/main.py\\\\\\\", line 79, in init\\\\n    driver_module.init()\\\\n  File \\\\\\\"score.py\\\\\\\", line 32, in init\\\\n    s = pickle.load(open('scaler.pkl','rb'))\\\\nAttributeError: Can't get attribute 'scaler' on <module '__main__' from '/opt/miniconda/bin/gunicorn'>\\\\n\\\", \\\"apiName\\\": \\\"\\\"}\", \"host\": \"wk-caas-895de745f7ba4271867822c90175767b-28255d2ca56dd042d2a6a2\", \"path\": \"/var/azureml-app/aml_logger.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"ERROR\", \"logger\": \"root\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-09T08:54:02.577790Z\", \"message\": \"Worker exiting (pid: 39)\", \"host\": \"wk-caas-895de745f7ba4271867822c90175767b-28255d2ca56dd042d2a6a2\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Worker exiting (pid: %s)\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-09T08:54:02.903803Z\", \"message\": \"Shutting down: Master\", \"host\": \"wk-caas-895de745f7ba4271867822c90175767b-28255d2ca56dd042d2a6a2\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Shutting down: %s\", \"stack_info\": null}\n",
      "{\"timestamp\": \"2019-01-09T08:54:02.904132Z\", \"message\": \"Reason: Worker failed to boot.\", \"host\": \"wk-caas-895de745f7ba4271867822c90175767b-28255d2ca56dd042d2a6a2\", \"path\": \"/opt/miniconda/lib/python3.6/site-packages/gunicorn/glogging.py\", \"tags\": \"%(module)s, %(asctime)s, %(levelname)s, %(message)s\", \"level\": \"INFO\", \"logger\": \"gunicorn.error\", \"msg\": \"Reason: %s\", \"stack_info\": null}\n",
      "2019-01-09T08:54:02,928150354+00:00 - gunicorn/finish 3 0\n",
      "2019-01-09T08:54:02,929317888+00:00 - Exit code 3 is not normal. Killing image.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('AssetData_Historical.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "with open('AssetData_Historical.csv') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    titles = reader.fieldnames\n",
    "    j_test = json.dumps({'data':[row for row in reader]})\n",
    "    \n",
    "result = service.run(input_data = j_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "with open('AssetData_Historical.csv') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    titles = reader.fieldnames\n",
    "    j_test = json.dumps({'data':[row for row in reader]})\n",
    "    \n",
    "def run(rawdata):\n",
    "    try:\n",
    "        df = json.loads(j_test)['data']\n",
    "        df = pd.DataFrame.from_records(df)\n",
    "        df['Latitude'] = cleanLongLat(df['Latitude'])\n",
    "        df['Longitude'] = cleanLongLat(df['Longitude'])\n",
    "        df.drop(['Machine_ID', 'District'], axis=1, inplace=True)\n",
    "        df.drop('Failure_NextHour', axis = 1, inplace=True)\n",
    "        df = df.apply(pd.to_numeric)\n",
    "        data = pca_transform.transform(scaler.scale(df))\n",
    "        result = best_model.predict(data) #Changed to best_model here\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})\n",
    "    return json.dumps({\"result\":result.tolist()}) #removed double brackets here\n",
    "\n",
    "run(j_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = json.loads(j_test)['data']\n",
    "df = pd.DataFrame.from_records(df)\n",
    "df['Latitude'] = cleanLongLat(df['Latitude'])\n",
    "df['Longitude'] = cleanLongLat(df['Longitude'])\n",
    "df.drop(['Machine_ID', 'District'], axis=1, inplace=True)\n",
    "df.drop('Failure_NextHour', axis = 1, inplace=True)\n",
    "data = pca_transform.transform(scaler.scale(df))\n",
    "result = best_model.predict(data) #Changed to best_model here\n",
    "\n",
    "df = json.loads(j_test)['data']\n",
    "df = pd.DataFrame.from_records(df)\n",
    "df['Latitude'] = cleanLongLat(df['Latitude'])\n",
    "df['Longitude'] = cleanLongLat(df['Longitude'])\n",
    "df.drop(['Machine_ID', 'District'], axis=1, inplace=True)\n",
    "df.drop('Failure_NextHour', axis = 1, inplace=True)\n",
    "df = df.apply(pd.to_numeric)\n",
    "data = pca_transform.transform(scaler.scale(df))\n",
    "\n",
    "df.apply(pd.to_numeric)\n",
    "#data = pca_transform.transform(scaler.scale(df))\n",
    "\n",
    "#pd.DataFrame.from_records(data['messages']).map.apply(pd.Series)\n",
    "pd.DataFrame.from_records(j_load)\n",
    "\n",
    "from utils import scaler, cleanLongLat\n",
    "\n",
    "pca_transform = pickle.load(open('pca_transform.pkl','rb'))\n",
    "scaler = pickle.load(open('scaler.pkl','rb'))\n",
    "\n",
    "\n",
    "#s = scaler_obj.scale(X)\n",
    "#p = pca_transform.transform(s)\n",
    "#j = json.dumps({'data':p.tolist()})\n",
    "\n",
    "#df = json.loads(j_test)['data']\n",
    "#df = pd.DataFrame.from_records(df)\n",
    "#df['Latitude'] = cleanLongLat(df['Latitude'])\n",
    "#df['Longitude'] = cleanLongLat(df['Longitude'])\n",
    "#df.drop(['Machine_ID', 'District'], axis=1, inplace=True)\n",
    "#df.drop('Failure_NextHour', axis = 1, inplace=True)\n",
    "#df = df.apply(pd.to_numeric)\n",
    "#data = pca_transform.transform(scaler.scale(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AzureML]",
   "language": "python",
   "name": "conda-env-AzureML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
